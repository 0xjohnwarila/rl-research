{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Synchronous Value Iteration\n",
    "***\n",
    "\n",
    "The goal of this assignment is to implement both single-core and distributed versions of syncronous value iteration (VI). In particuar, VI will be applied to Markov Decision Processes (MDPs) in order to compute policies that optimize expected infinite horizon discounted cummulative reward. \n",
    "\n",
    "The relevant content about MDPs and VI are in the following course notes from CS533. \n",
    "\n",
    "https://oregonstate.instructure.com/courses/1719746/files/74716197/download?wrap=1\n",
    "https://oregonstate.instructure.com/courses/1719746/files/74828408/download?wrap=1\n",
    "\n",
    "\n",
    "### Synchronous Value Iteration Recap\n",
    "\n",
    "Below is a review of the synchronous value iteration algorithm. The algorithm is iterative and each iteration produces a newly updated value function $V_{new}$ based on the value function from the previous iteration $V_{curr}$. This is done by applying the Bellman backup operator to $V_{curr}$ at each state. That is, \n",
    "\\begin{equation}\n",
    "V_{new}(s) = \\max_{a\\in A} R(s,a) + \\beta \\sum_{s'\\in S} T(s,a,s') V_{curr}(s')\n",
    "\\end{equation}\n",
    "where $\\beta \\in [0,1)$ is the discount factor, $R$ is the reward function, and $T$ is the transition function. \n",
    "\n",
    "The algorithm also maintains the greedy policy $\\pi$ at each iteration, which is based on a one-step look ahead operator: \n",
    "\\begin{equation}\n",
    "\\pi_{curr}(s) = \\arg\\max_{a\\in A} R(s,a) + \\beta \\sum_{s'\\in S} T(s,a,s') V_{curr}(s')\n",
    "\\end{equation}\n",
    "\n",
    "After an update we define the Bellman error of that iteration as $\\max_s |V_{new}(s)-V_{curr}(s)|$. In the notes, it is shown that this error allows us to bound the difference between the value function of $\\pi_{curr}$ and the optimal value function $V^{*}$. Thus, a typical stopping condition for VI is to iterate until the Bellman error is below a specified threshold $\\epsilon$. Putting everything together, the overall algorithm is as follows:\n",
    "\n",
    "- Start with $V_{curr}(s) = 0$ for all $s$\n",
    "- error = $\\infty$\n",
    "- While error > $\\epsilon$ \n",
    "    - For each state $s$ \n",
    "        - $V_{new}(s) = \\max_{a\\in A} R(s,a) + \\beta \\sum_{s'\\in S} T(s,a,s') V_{curr}(s')$\n",
    "        - $\\pi_{curr}(s) = \\arg\\max_{a\\in A} R(s,a) + \\beta \\sum_{s'\\in S} T(s,a,s') V_{curr}(s')$\n",
    "    - error = $\\max_s |V_{new}(s)-V_{curr}(s)|$   ;; could do this incrementally      \n",
    "    - $V_{curr} = V_{new}$\n",
    "\n",
    "The reason we refer to this version of VI as synchronous is because it maintains both a current and new value function, where all values of the new value function are computed based on the fixed current value function. That is, each iteration updates all states based on the value function of the previous iteration. \n",
    "\n",
    "To simplify this first assignment, we have decided to focus on Synchronous VI and to investigate how to best create a distributed implementation using the Ray framework. In particular, a distributed version of Synchronous VI should still produce a sequence of value functions and policies that are equivalent to those that would be produced by a single-core version, but ideally do so much faster. The remainder of this notebook guides you through some of the MDP mechanics and algorithm implementations. The grand finale of this first assignment is a competition where you will try to develop the fasted distributed implementation that you can. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/11/06958a2b895a3853206dea1fb2a5b11bf044f626f90745987612af9c8f2c/matplotlib-3.1.2-cp36-cp36m-manylinux1_x86_64.whl (13.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.1MB 98kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib)\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/a1/5742b56282449b1c0968197f63eae486eca2c35dcd334bab75ad524e0de1/kiwisolver-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.11 (from matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting six (from cycler>=0.10->matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting setuptools (from kiwisolver>=1.0.1->matplotlib)\n",
      "  Using cached https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl\n",
      "Installing collected packages: six, cycler, python-dateutil, setuptools, kiwisolver, pyparsing, numpy, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.1.0 matplotlib-3.1.2 numpy-1.18.0 pyparsing-2.4.6 python-dateutil-2.8.1 setuptools-42.0.2 six-1.13.0\n"
     ]
    }
   ],
   "source": [
    "# You will need to uncomment the following pip commands if the libraries need to be installed. \n",
    "# You may get some errors related to readchar, but they should not break the project.\n",
    "\n",
    "#!pip3 install --user readchar\n",
    "#!pip3 install --user gym\n",
    "#!pip3 install --user psutil\n",
    "!pip3 install --user matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint, choice\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## FrozenLake\n",
    "\n",
    "We will use the FrozenLake environment as the MDP environment for this experiment. This is a type of gridworld environment, whose size (number of states) can be controlled by adjusting the grid dimensions. The environment is intended to model the process of navigating a frozen lake, while avoiding falling into holes with the objective of reaching a goal location. \n",
    "\n",
    "The environment is defined as follows:\n",
    "\n",
    "- The environment is a rectangular grid of states/cells. There are four different types of cells as indicated by the following cell labels: \n",
    "\n",
    "    - S labels the starting/initial cell, always in the top left corner\n",
    "    \n",
    "    - F labels frozen cells that are safe to step on\n",
    "\n",
    "    - H labels holes and if the agent enters a hole cell there is a pentalty of -1000 and the episode ends\n",
    "\n",
    "    - G labels the goal cell and when reached gives a reward of 1000 and the episode ends\n",
    "\n",
    "- There are four possible actions (Left, Right, Down, Up). \n",
    "\n",
    "- The transition function moves the agent in the expected direction with 0.7 probability, and there is a 0.3 probability of transitioning to one of the other randomly selected directions. \n",
    "\n",
    "- There is a reward of -1 for each action taken by the agent, which is intended to encourage the agent to reach the goal as fast as possible. \n",
    "\n",
    "- Episodes end whenever the agent falls in a hole or reaches the goal. An end-of-episode is modeled by transitioning to a zero-reward terminal state (all actions lead to that state). \n",
    "   \n",
    "Below is the code for the FrozenLake environment class, which has the following functions that will be used in this assignment: \n",
    "\n",
    "- FrozenLake.GetSuccesors() : Take a state and an action as input, and return a list of pairs, where each pair $(s',p)$ is a successor state $s'$ with non-zero probability and $p$ is the probability of transitioning to $p$.  \n",
    "\n",
    "- FrozenLake.GetTransitionProb() : Take a state, an action, a next state as input, and return the probability of the transition \n",
    "\n",
    "- FrozenLake.GetReward() : Take a state and an action as input, and return the reward of that.\n",
    "\n",
    "The version we are using for the assignment 2 is a modified version of the environment at the following location.   \n",
    "  \n",
    "Source: https://github.com/openai/gym/blob/master/gym/envs/toy_text/frozen_lake.py  \n",
    "\n",
    "Execute the following cell to initialize the MDP environments. (You do not need to change the code in this part.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from contextlib import closing\n",
    "\n",
    "import numpy as np\n",
    "from six import StringIO, b\n",
    "\n",
    "from gym import utils\n",
    "from gym.envs.toy_text import discrete\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "np.set_printoptions(threshold=sys.maxsize, linewidth=sys.maxsize, precision = 2)\n",
    "TransitionProb = [0.7, 0.1, 0.1, 0.1]\n",
    "def generate_row(length, h_prob):\n",
    "    row = np.random.choice(2, length, p=[1.0 - h_prob, h_prob])\n",
    "    row = ''.join(list(map(lambda z: 'F' if z == 0 else 'H', row)))\n",
    "    return row\n",
    "\n",
    "\n",
    "def generate_map(shape):\n",
    "    \"\"\"\n",
    "\n",
    "    :param shape: Width x Height\n",
    "    :return: List of text based map\n",
    "    \"\"\"\n",
    "    h_prob = 0.1\n",
    "    grid_map = []\n",
    "\n",
    "    for h in range(shape[1]):\n",
    "\n",
    "        if h == 0:\n",
    "            row = 'SF'\n",
    "            row += generate_row(shape[0] - 2, h_prob)\n",
    "        elif h == 1:\n",
    "            row = 'FF'\n",
    "            row += generate_row(shape[0] - 2, h_prob)\n",
    "\n",
    "        elif h == shape[1] - 1:\n",
    "            row = generate_row(shape[0] - 2, h_prob)\n",
    "            row += 'FG'\n",
    "        elif h == shape[1] - 2:\n",
    "            row = generate_row(shape[0] - 2, h_prob)\n",
    "            row += 'FF'\n",
    "        else:\n",
    "            row = generate_row(shape[0], h_prob)\n",
    "\n",
    "        grid_map.append(row)\n",
    "        del row\n",
    "\n",
    "    return grid_map\n",
    "\n",
    "\n",
    "\n",
    "MAPS = {\n",
    "    \n",
    "    \"4x4\": [\n",
    "        \"SFFF\",\n",
    "        \"FHFH\",\n",
    "        \"FFFH\",\n",
    "        \"HFFG\"\n",
    "    ],\n",
    "    \"8x8\": [\n",
    "        \"SFFFFFFF\",\n",
    "        \"FFFFFFFF\",\n",
    "        \"FFFHFFFF\",\n",
    "        \"FFFFFHFF\",\n",
    "        \"FFFHFFFF\",\n",
    "        \"FHHFFFHF\",\n",
    "        \"FHFFHFHF\",\n",
    "        \"FFFHFFFG\"\n",
    "    ],\n",
    "    \"16x16\": [\n",
    "        \"SFFFFFFFFHFFFFHF\",\n",
    "        \"FFFFFFFFFFFFFHFF\",\n",
    "        \"FFFHFFFFHFFFFFFF\",\n",
    "        \"FFFFFFFFHFFFFFFF\",\n",
    "        \"FFFFFFFFFFFFFFFF\",\n",
    "        \"FFHHFFFFFFFHFFFH\",\n",
    "        \"FFFFFFFFFFFFFFFF\",\n",
    "        \"FFFFFHFFFFFFHFFF\",\n",
    "        \"FFFFFHFFFFFFFFFH\",\n",
    "        \"FFFFFFFHFFFFFFFF\",\n",
    "        \"FFFFFFFFFFFFHFFF\",\n",
    "        \"FFFFFFHFFFFFFFFF\",\n",
    "        \"FFFFFFFFHFFFFFFF\",\n",
    "        \"FFFFFFFFFHFFFFHF\",\n",
    "        \"FFFFFFFFFFHFFFFF\",\n",
    "        \"FFFHFFFFFFFFFFFG\",\n",
    "    ],\n",
    "    \n",
    "    \"32x32\": [\n",
    "        'SFFHFFFFFFFFFFFFFFFFFFFFFFHFFFFF',\n",
    "        'FFHFHHFFHFFFFFFFFFFFFFFFFFHFFFFF',\n",
    "        'FFFHFFFFFFFFHFFHFFFFFFFFFFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFHFHHFHFHFFFFFHFFFH',\n",
    "        'FFFFHFFFFFFFFFFFFFFFHFHFFFFFFFHF',\n",
    "        'FFFFFHFFFFFFFFFFHFFFFFFFFFFHFFFF',\n",
    "        'FFHHFFFFHFFFFFFFFFFFFFFFFFFFFFFF',\n",
    "        'FFFHFFFFFFFFFFHFFFHFHFFFFFFFFHFF',\n",
    "        'FFFFHFFFFFFHFFFFHFHFFFFFFFFFFFFH',\n",
    "        'FFFFHHFHFFFFHFFFFFFFFFFFFFFFFFFF',\n",
    "        'FHFFFFFFFFFFHFFFFFFFFFFFHHFFFHFH',\n",
    "        'FFFHFFFHFFFFFFFFFFFFFFFFFFFFHFFF',\n",
    "        'FFFHFHFFFFFFFFHFFFFFFFFFFFFHFFHF',\n",
    "        'FFFFFFFFFFFFFFFFHFFFFFFFHFFFFFFF',\n",
    "        'FFFFFFHFFFFFFFFHHFFFFFFFHFFFFFFF',\n",
    "        'FFHFFFFFFFFFHFFFFFFFFFFHFFFFFFFF',\n",
    "        'FFFHFFFFFFFFFHFFFFHFFFFFFHFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFFFFFFFFFFFFHFFFFF',\n",
    "        'FFFFFFFFHFFFFFFFHFFFFFFFFFFFFFFH',\n",
    "        'FFHFFFFFFFFFFFFFFFHFFFFFFFFFFFFF',\n",
    "        'FFFFFFFHFFFFFFFFFFFFFFFFFFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFHFFFFHFFFFFFFHFFF',\n",
    "        'FFHFFFFHFFFFFFFFFHFFFFFFFFFFFHFH',\n",
    "        'FFFFFFFFFFHFFFFHFFFFFFFFFFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFFFHHFFHHHFFFHFFFF',\n",
    "        'FFFFFFFFFFFFFFHFFFFHFFFFFFFHFFFF',\n",
    "        'FFFFFFFHFFFFFFFFFFFFFFFFFFFFFFFF',\n",
    "        'FFFFFHFFFFFFFFFFFFFFFFHFFHFFFFFF',\n",
    "        'FFFFFFFHFFFFFFFFFHFFFFFFFFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFFFFFFFFFFHFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFFFFFFFFFFHFFFFFFF',\n",
    "        'FFFFFFFFFFFFFFFHFFFFFFFFHFFFFFFG',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def generate_random_map(size=8, p=0.8):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "\n",
    "    # BFS to check that it's a valid path.\n",
    "    def is_valid(arr, r=0, c=0):\n",
    "        if arr[r][c] == 'G':\n",
    "            return True\n",
    "\n",
    "        tmp = arr[r][c]\n",
    "        arr[r][c] = \"#\"\n",
    "\n",
    "        # Recursively check in all four directions.\n",
    "        directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "        for x, y in directions:\n",
    "            r_new = r + x\n",
    "            c_new = c + y\n",
    "            if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                continue\n",
    "\n",
    "            if arr[r_new][c_new] not in '#H':\n",
    "                if is_valid(arr, r_new, c_new):\n",
    "                    arr[r][c] = tmp\n",
    "                    return True\n",
    "\n",
    "        arr[r][c] = tmp\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "\n",
    "class FrozenLakeEnv(discrete.DiscreteEnv):\n",
    "    \"\"\"\n",
    "    Winter is here. You and your friends were tossing around a frisbee at the park\n",
    "    when you made a wild throw that left the frisbee out in the middle of the lake.\n",
    "    The water is mostly frozen, but there are a few holes where the ice has melted.\n",
    "    If you step into one of those holes, you'll fall into the freezing water.\n",
    "    At this time, there's an international frisbee shortage, so it's absolutely imperative that\n",
    "    you navigate across the lake and retrieve the disc.\n",
    "    However, the ice is slippery, so you won't always move in the direction you intend.\n",
    "    The surface is described using a grid like the following\n",
    "\n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    "\n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    "\n",
    "    The episode ends when you reach the goal or fall in a hole.\n",
    "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {'render.modes': ['human', 'ansi']}\n",
    "\n",
    "    def __init__(self, desc=None, map_name=\"4x4\",is_slippery=True):\n",
    "        if desc is None and map_name is None:\n",
    "            desc = generate_random_map()\n",
    "        elif desc is None:\n",
    "            desc = MAPS[map_name]\n",
    "        self.desc = desc = np.asarray(desc,dtype='c')\n",
    "        self.nrow, self.ncol = nrow, ncol = desc.shape\n",
    "        self.reward_range = (0, 1)\n",
    "\n",
    "        nA = 4\n",
    "        nS = nrow * ncol\n",
    "\n",
    "        isd = np.array(desc == b'S').astype('float64').ravel()\n",
    "        isd /= isd.sum()\n",
    "\n",
    "        rew_hole = -1000\n",
    "        rew_goal = 1000\n",
    "        rew_step = -1\n",
    "        \n",
    "        P = {s : {a : [] for a in range(nA)} for s in range(nS)}\n",
    "        self.TransitProb = np.zeros((nA, nS + 1, nS + 1))\n",
    "        self.TransitReward = np.zeros((nS + 1, nA))\n",
    "        \n",
    "        def to_s(row, col):\n",
    "            return row*ncol + col\n",
    "        \n",
    "        def inc(row, col, a):\n",
    "            if a == LEFT:\n",
    "                col = max(col-1,0)\n",
    "            elif a == DOWN:\n",
    "                row = min(row+1,nrow-1)\n",
    "            elif a == RIGHT:\n",
    "                col = min(col+1,ncol-1)\n",
    "            elif a == UP:\n",
    "                row = max(row-1,0)\n",
    "            return (row, col)\n",
    "\n",
    "        for row in range(nrow):\n",
    "            for col in range(ncol):\n",
    "                s = to_s(row, col)\n",
    "                for a in range(4):\n",
    "                    li = P[s][a]\n",
    "                    letter = desc[row, col]\n",
    "                    if letter in b'H':\n",
    "                        li.append((1.0, s, 0, True))\n",
    "                        self.TransitProb[a, s, nS] = 1.0\n",
    "                        self.TransitReward[s, a] = rew_hole\n",
    "                    elif letter in b'G':\n",
    "                        li.append((1.0, s, 0, True))\n",
    "                        self.TransitProb[a, s, nS] = 1.0\n",
    "                        self.TransitReward[s, a] = rew_goal\n",
    "                    else:\n",
    "                        if is_slippery:\n",
    "                            #for b in [(a-1)%4, a, (a+1)%4]:\n",
    "                            for b, p in zip([a, (a+1)%4, (a+2)%4, (a+3)%4], TransitionProb):\n",
    "                                newrow, newcol = inc(row, col, b)\n",
    "                                newstate = to_s(newrow, newcol)\n",
    "                                newletter = desc[newrow, newcol]\n",
    "                                done = bytes(newletter) in b'GH'\n",
    "                                #rew = float(newletter == b'G')\n",
    "                                #li.append((1.0/10.0, newstate, rew, done))\n",
    "                                if newletter == b'G':\n",
    "                                    rew = rew_goal\n",
    "                                elif newletter == b'H':\n",
    "                                    rew = rew_hole\n",
    "                                else:\n",
    "                                    rew = rew_step\n",
    "                                li.append((p, newstate, rew, done))\n",
    "                                self.TransitProb[a, s, newstate] += p\n",
    "                                self.TransitReward[s, a] = rew_step\n",
    "                        else:\n",
    "                            newrow, newcol = inc(row, col, a)\n",
    "                            newstate = to_s(newrow, newcol)\n",
    "                            newletter = desc[newrow, newcol]\n",
    "                            done = bytes(newletter) in b'GH'\n",
    "                            rew = float(newletter == b'G')\n",
    "                            li.append((1.0, newstate, rew, done))\n",
    "\n",
    "        super(FrozenLakeEnv, self).__init__(nS, nA, P, isd)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        outfile = StringIO() if mode == 'ansi' else sys.stdout\n",
    "\n",
    "        row, col = self.s // self.ncol, self.s % self.ncol\n",
    "        desc = self.desc.tolist()\n",
    "        desc = [[c.decode('utf-8') for c in line] for line in desc]\n",
    "        desc[row][col] = utils.colorize(desc[row][col], \"red\", highlight=True)\n",
    "        if self.lastaction is not None:\n",
    "            outfile.write(\"  ({})\\n\".format([\"Left\",\"Down\",\"Right\",\"Up\"][self.lastaction]))\n",
    "        else:\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.write(\"\\n\".join(''.join(line) for line in desc)+\"\\n\")\n",
    "\n",
    "        if mode != 'human':\n",
    "            with closing(outfile):\n",
    "                return outfile.getvalue()\n",
    "    \n",
    "    def GetSuccessors(self, s, a):\n",
    "        next_states = np.nonzero(self.TransitProb[a, s, :])\n",
    "        probs = self.TransitProb[a, s, next_states]\n",
    "        return [(s,p) for s,p in zip(next_states[0], probs[0])]\n",
    "    \n",
    "    def GetTransitionProb(self, s, a, ns):\n",
    "        return self.TransitProb[a, s, ns]\n",
    "    \n",
    "    def GetReward(self, s, a):\n",
    "        return self.TransitReward[s, a]\n",
    "    \n",
    "    def GetStateSpace(self):\n",
    "        return self.TransitProb.shape[1]\n",
    "    \n",
    "    def GetActionSpace(self):\n",
    "        return self.TransitProb.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Game\n",
    "Have Fun!  \n",
    "(You don't have to do this part, but if you do make sure to use quite using \"q\" so that you can continue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------actions--------\n",
      "a: Left\n",
      "s: Down\n",
      "d: Right\n",
      "w: Up\n",
      "(q: quit)\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFFFFHFF\n",
      "FFFHFFFFHFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFHHFFFFFFFHFFFH\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFHFFFFFFHFFF\n",
      "FFFFFHFFFFFFFFFH\n",
      "FFFFFFFHFFFFFFFF\n",
      "FFFFFFFFFFFFHFFF\n",
      "FFFFFFHFFFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFHFFFFF\n",
      "FFFHFFFFFFFFFFFG\n",
      "input action: d\n",
      "\u001b[2J\n",
      "---------actions--------\n",
      "a: Left\n",
      "s: Down\n",
      "d: Right\n",
      "w: Up\n",
      "(q: quit)\n",
      "\n",
      "current state:1\n",
      "move to expected direstion\n",
      "probabilty: 0.7\n",
      "current reward:-1\n",
      "\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFFFFHFF\n",
      "FFFHFFFFHFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFHHFFFFFFFHFFFH\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFHFFFFFFHFFF\n",
      "FFFFFHFFFFFFFFFH\n",
      "FFFFFFFHFFFFFFFF\n",
      "FFFFFFFFFFFFHFFF\n",
      "FFFFFFHFFFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFHFFFFF\n",
      "FFFHFFFFFFFFFFFG\n",
      "\n",
      "input action: d\n",
      "\u001b[2J\n",
      "---------actions--------\n",
      "a: Left\n",
      "s: Down\n",
      "d: Right\n",
      "w: Up\n",
      "(q: quit)\n",
      "\n",
      "current state:2\n",
      "move to expected direstion\n",
      "probabilty: 0.7\n",
      "current reward:-2\n",
      "\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFFFHFFFFHF\n",
      "FFFFFFFFFFFFFHFF\n",
      "FFFHFFFFHFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFHHFFFFFFFHFFFH\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFHFFFFFFHFFF\n",
      "FFFFFHFFFFFFFFFH\n",
      "FFFFFFFHFFFFFFFF\n",
      "FFFFFFFFFFFFHFFF\n",
      "FFFFFFHFFFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFHFFFFF\n",
      "FFFHFFFFFFFFFFFG\n",
      "\n",
      "input action: d\n",
      "\u001b[2J\n",
      "---------actions--------\n",
      "a: Left\n",
      "s: Down\n",
      "d: Right\n",
      "w: Up\n",
      "(q: quit)\n",
      "\n",
      "current state:3\n",
      "move to expected direstion\n",
      "probabilty: 0.7\n",
      "current reward:-3\n",
      "\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0mFFFFFHFFFFHF\n",
      "FFFFFFFFFFFFFHFF\n",
      "FFFHFFFFHFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFHHFFFFFFFHFFFH\n",
      "FFFFFFFFFFFFFFFF\n",
      "FFFFFHFFFFFFHFFF\n",
      "FFFFFHFFFFFFFFFH\n",
      "FFFFFFFHFFFFFFFF\n",
      "FFFFFFFFFFFFHFFF\n",
      "FFFFFFHFFFFFFFFF\n",
      "FFFFFFFFHFFFFFFF\n",
      "FFFFFFFFFHFFFFHF\n",
      "FFFFFFFFFFHFFFFF\n",
      "FFFHFFFFFFFFFFFG\n",
      "\n",
      "input action: q\n"
     ]
    }
   ],
   "source": [
    "print(\"---------actions--------\")\n",
    "print(\"a: Left\\ns: Down\\nd: Right\\nw: Up\\n(q: quit)\")\n",
    "env = FrozenLakeEnv(map_name=\"16x16\")\n",
    "env.render()\n",
    "rew = 0\n",
    "for _ in range(1000):\n",
    "    a = input(\"input action: \")\n",
    "    if a == 'a':\n",
    "        a = 0\n",
    "    elif a == 's':\n",
    "        a = 1\n",
    "    elif a == 'd':\n",
    "        a = 2\n",
    "    elif a == 'w':\n",
    "        a = 3\n",
    "    elif a == 'q':\n",
    "        break\n",
    "    else:\n",
    "        print('illegal input')\n",
    "        continue\n",
    "    observation, reward, done, info = env.step(a)\n",
    "    rew += reward\n",
    "    print(chr(27) + \"[2J\")\n",
    "    print(\"---------actions--------\")\n",
    "    print(\"a: Left\\ns: Down\\nd: Right\\nw: Up\\n(q: quit)\")\n",
    "    print()\n",
    "    print(\"current state:\" + str(observation))\n",
    "    if info['prob'] == TransitionProb[0] or info['prob'] == 1:\n",
    "        print('move to expected direstion')\n",
    "    else:\n",
    "        print('move to unexpected direstion')\n",
    "    print(\"probabilty: \" + str(info['prob']))\n",
    "    print(\"current reward:\" + str(rew))\n",
    "    print()\n",
    "    env.render()\n",
    "    print()\n",
    "    if done:\n",
    "        print('end')\n",
    "        break\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Initializations\n",
    "\n",
    "Run the following cell to initilize maps of different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_8 = (MAPS[\"8x8\"], 8)\n",
    "map_16 = (MAPS[\"16x16\"], 16)\n",
    "map_32 = (MAPS[\"32x32\"], 32)\n",
    "#map_50 = (generate_map((50,50)), 50)\n",
    "#map_110 = (generate_map((110,110)), 110)\n",
    "\n",
    "MAP = map_8\n",
    "map_size = MAP[1]\n",
    "run_time = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Policy Evaluation \n",
    "\n",
    "As a warm up we are going to get experience running a policy in an MDP to empirically evalute the performance of the policy. \n",
    "\n",
    "Run the following cell to define the policy evaluation function, which allows us to run a specified policy in a specified environment for a specified number of trials. The function assumes that the trials will terminate for any policy, which is indicated by the \"done\" variable returned by the environment. This version of the function measures performance by total cummulative reward. Since the environment is stochastic each trial may return a different total reward. This function returns the average cummulative reward across the trials. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env, policy, trials = 1000):\n",
    "    total_reward = 0\n",
    "    for _ in range(trials):\n",
    "        env.reset()\n",
    "        done = False\n",
    "        observation, reward, done, info = env.step(policy[0])\n",
    "        total_reward += reward\n",
    "        while not done:\n",
    "            observation, reward, done, info = env.step(policy[observation])\n",
    "            total_reward += reward\n",
    "    return total_reward / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discounted Policy Evaluation \n",
    "Create a modified version of the above evaluation function that measure the discounted total reward rather than just the total reward as above. The discount factor is specified via a parameter to the function. Specifically, if a trial results in a sequence of rewards: $r_0, r_1, r_2, r_3$ the discounted total reward would be $r_0 + \\beta r_1 + \\beta^2 r_2 + \\beta^3 r_3$, where $\\beta$ is the discount factor.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy_discounted(env, policy, discount_factor, trials = 1000):\n",
    "    total_reward = 0\n",
    "    for _ in range(trials):\n",
    "        env.reset()\n",
    "        done = False\n",
    "        i = 0\n",
    "        observation, reward, done, info = env.step(policy[0])\n",
    "        total_reward += (discount_factor**i)*reward\n",
    "        while not done:\n",
    "            i += 1\n",
    "            observation, reward, done, info = env.step(policy[observation])\n",
    "            total_reward += (discount_factor**i)*reward\n",
    "    return total_reward / trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "Execute the following cell to define the print function. This function shows the policy and state values and saves them to disk. We will use this later in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(v, pi, map_size, env, beta, name):\n",
    "    v_np, pi_np  = np.array(v), np.array(pi)\n",
    "    print(\"\\nState Value:\\n\")\n",
    "    print(np.array(v_np[:-1]).reshape((map_size,map_size)))\n",
    "    print(\"\\nPolicy:\\n\")\n",
    "    print(np.array(pi_np[:-1]).reshape((map_size,map_size)))\n",
    "    print(\"\\nAverage reward: {}\\n\".format(evaluate_policy(env, pi)))\n",
    "    print(\"Avereage discounted reward: {}\\n\".format(evaluate_policy_discounted(env, pi, discount_factor = beta)))\n",
    "    print(\"State Value image view:\\n\")\n",
    "    plt.imshow(np.array(v_np[:-1]).reshape((map_size,map_size)))\n",
    "    \n",
    "    pickle.dump(v, open(name + \"_\" + str(map_size) + \"_v.pkl\", \"wb\"))\n",
    "    pickle.dump(pi, open(name + \"_\" + str(map_size) + \"_pi.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random policy  \n",
    "To provide a reference point for policy performance the following cell defines a random policy (selects actions uniformly at random) and evaluates it. Execute the cell and observe the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "[3, 3, 2, 0, 1, 3, 0, 0, 0, 2, 0, 2, 3, 0, 2, 2, 0, 1, 0, 1, 0, 2, 3, 3, 2, 0, 3, 1, 2, 0, 0, 2, 1, 1, 3, 3, 3, 2, 2, 1, 1, 0, 1, 2, 0, 1, 1, 2, 3, 0, 2, 0, 3, 3, 2, 3, 2, 0, 3, 0, 3, 1, 0, 0]\n",
      "Average reward: -1062.719\n",
      "Average discounted reward: -998.1445826533313\n"
     ]
    }
   ],
   "source": [
    "env = FrozenLakeEnv(desc = MAP[0], is_slippery = True)\n",
    "env.render()\n",
    "pi = [0] * map_size * map_size\n",
    "for i in range(map_size * map_size):\n",
    "    pi[i] = randint(0, 3)\n",
    "print(pi)\n",
    "print(\"Average reward:\", evaluate_policy(env, pi))\n",
    "print(\"Average discounted reward:\", \n",
    "      evaluate_policy_discounted(env, pi, discount_factor = 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Synchronous Value Iteration with full transition function\n",
    "\n",
    "In this section, you should implement the synchronous value iteration algorithm. A code skeleton is provided below. Complete the given code by implementing the Bellman backup operator. Recall that the Bellman backup for a state assuming the current value function is $V$ is given by:\n",
    "\\begin{equation}\n",
    "V_{new}(s) = \\max_{a\\in A} R(s,a) + \\beta \\sum_{s'\\in S} T(s,a,s') V(s')\n",
    "\\end{equation}\n",
    "\n",
    "For this part of the assignment you should implement this Bellman backup operator in a way that performs the sum over all possible next states $s' \\in S$. You will want to use the functions env.GetTransitionProb() to get the transition probabilities and env.GetReward() to get the rewards. In each iteration you need to do the following:\n",
    "\n",
    "1. Apply the Bellman backup to all state. \n",
    "2. Compute and update the Bellman error (see first part of document).\n",
    "3. Update the value and policy accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_value_iteration_v1(env, beta = 0.999, epsilon = 0.0001):\n",
    "    \n",
    "    A = env.GetActionSpace()\n",
    "    S = env.GetStateSpace()\n",
    "    \n",
    "    pi = [0] * S\n",
    "    v = [0] * S\n",
    "    \n",
    "    pi_new = [0] * S\n",
    "    v_new = [0] * S\n",
    "    \n",
    "    bellman_error = float('inf')\n",
    "    while(bellman_error > epsilon):\n",
    "        bellman_error = 0\n",
    "        for state in range(S):\n",
    "            max_v = float('-inf')\n",
    "            max_a = 0\n",
    "            for action in range(A):\n",
    "                reward = env.GetReward(state, action)\n",
    "                state_sum = 0\n",
    "                for state_prime in range(S):\n",
    "                    state_sum += env.GetTransitionProb(state, action, state_prime) * v[state_prime]\n",
    "                state_sum *= beta\n",
    "                reward += state_sum\n",
    "                if reward > max_v:\n",
    "                    max_v = reward\n",
    "                    max_a = action\n",
    "            \n",
    "            #Update the policy and the v\n",
    "            pi_new[state] = max_a\n",
    "            v_new[state] = max_v\n",
    "            #Update the error\n",
    "            error = abs(v_new[state] - v[state])\n",
    "            if error > bellman_error:\n",
    "                bellman_error = error\n",
    "                \n",
    "        v = deepcopy(v_new)\n",
    "        pi = deepcopy(pi_new)\n",
    "        \n",
    "    return v, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see the output of your function and store the value and policy matrices to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Map:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "time: 0.7277002334594727\n",
      "\n",
      "State Value:\n",
      "\n",
      "[[  363.5    365.91   369.38   376.73   400.45   411.84   418.7    422.15]\n",
      " [  360.24   357.72   335.12   231.84   358.44   389.37   415.63   424.67]\n",
      " [  353.55   333.99   189.29 -1000.     173.63   227.87   389.72   428.36]\n",
      " [  339.83   306.42   225.01   -42.34    11.12 -1000.     269.05   436.45]\n",
      " [  290.6    139.46   -29.52 -1000.     -51.75    81.41   258.29   463.58]\n",
      " [  110.07 -1000.   -1000.    -309.32   -88.99    68.62 -1000.     498.87]\n",
      " [  -32.47 -1000.    -463.4   -463.4  -1000.     243.49 -1000.     720.18]\n",
      " [  -53.06  -187.65  -309.32 -1000.     262.9    625.53   734.24  1000.  ]]\n",
      "\n",
      "Policy:\n",
      "\n",
      "[[2 2 2 2 2 2 2 1]\n",
      " [3 3 3 3 3 2 2 1]\n",
      " [3 3 3 0 3 2 2 1]\n",
      " [3 0 0 0 3 0 2 1]\n",
      " [3 3 3 0 2 2 2 1]\n",
      " [3 0 0 2 2 1 0 1]\n",
      " [3 0 1 3 0 1 0 1]\n",
      " [3 0 0 0 2 2 2 0]]\n",
      "\n",
      "Average reward: 399.375\n",
      "\n",
      "Avereage discounted reward: 368.38021971827413\n",
      "\n",
      "State Value image view:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAALgUlEQVR4nO3df6jddR3H8ddr997NuenEXCKbuGUmmJCTsbCFkGJpikYUzNBICiFQlAKb/dd/9Y/oH7IYUxM0raaCiGmCiinLdHOV25ysYewubRs255Z2d+/e/XHP7E437/ec+/1+vue+fT7gsvOL834f7l73+z3f8z2ftyNCAPKY0XYDAOpFqIFkCDWQDKEGkiHUQDKDTTzp0LzZMevUeU08daucuKCV81OQrL+z997ap5G97x21WiOhnnXqPJ1353ebeOpWzXDZ//guWG/mjLFitUq+rtK/s1L1Xrj+N8fuoUgHAIoh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkqkUatuX2t5qe5vtlU03BaB3k4ba9oCkOyVdJukcSVfbPqfpxgD0psqWepmkbRGxPSJGJD0o6apm2wLQqyqhXiBpx4Trw53bjmD7etsv23559J336uoPQJdqO1AWEasjYmlELB2cN7uupwXQpSqh3inp9AnXF3ZuA9CHqoT6JUln2V5se6akFZIebbYtAL2adJGEiBi1fYOkJyUNSLo7IjY13hmAnlRa+SQiHpf0eMO9AKgBZ5QByRBqIBlCDSRDqIFkCDWQDKEGkiHUQDKNTOgo6VCUG6wyMjZQrJYk7d1f7hz6U048UKzWrMHRcrUGytXqF2ypgWQINZAMoQaSIdRAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kEyVCR13295l+9USDQGYmipb6l9JurThPgDUZNJQR8Rzkt4u0AuAGtT2npqxO0B/YOwOkAxHv4FkCDWQTJWPtB6QtE7S2baHbX+/+bYA9KrKLK2rSzQCoB7sfgPJEGogGUINJEOogWQINZAMoQaSIdRAMo2N3Sk1Dmf0ULm/S3v2zi1WS5LO/M7GYrW23bekWK2hmeVG4Sw4+Z1itSRp9uDBovWOhi01kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkqmyRtnptp+xvdn2Jts3lWgMQG+qnPs9KunHEbHB9gmS1tt+KiI2N9wbgB5UGbvzZkRs6Fx+V9IWSQuabgxAb7p6T217kaQlkl48yn0fjN05yNgdoDWVQ217rqSHJN0cEfs+fP/EsTtDjN0BWlMp1LaHNB7o+yPi4WZbAjAVVY5+W9JdkrZExG3NtwRgKqpsqZdLulbSRbY3dn6+3nBfAHpUZezO85LKrE0EYMo4owxIhlADyRBqIBlCDSRDqIFkCDWQDKEGkiHUQDKNzNIKWWOFZmkdHCv3d2lg4FCxWpK0/RcXlCu2J4qVOuPmV4rV+ucj5xSrJUmLT367SB3r2L8vttRAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kAyhBpIh1EAyVRYePM72n23/pTN252clGgPQmyqnif5X0kURsb+zVPDztn8fEX9quDcAPaiy8GBI2t+5OtT5KXeiMICuVF3Mf8D2Rkm7JD0VER87dmf0nf/U3SeAiiqFOiLGIuI8SQslLbN97lEe88HYncF5x9fdJ4CKujr6HRF7JT0j6dJm2gEwVVWOfs+3fVLn8mxJl0h6renGAPSmytHv0yTda3tA438EfhsRjzXbFoBeVTn6/VeNz6QGMA1wRhmQDKEGkiHUQDKEGkiGUAPJEGogGUINJEOogWSaGbsT1vsjQ0089UfsfXtOkTqSNLBnZrFaknTmT9YVq7X95+VG/Lz+y2XFas2JA8VqSdJxAweL1GHsDvAJQqiBZAg1kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkKoe6s6D/K7ZZdBDoY91sqW+StKWpRgDUo+rYnYWSLpe0ptl2AExV1S317ZJukXToWA84cpZW2W/GAPi/KhM6rpC0KyLWf9zjjpylVe7rkACOVGVLvVzSlbbfkPSgpIts39doVwB6NmmoI+LWiFgYEYskrZD0dERc03hnAHrC59RAMl0tZxQRz0p6tpFOANSCLTWQDKEGkiHUQDKEGkiGUAPJEGogGUINJNPI2J2xgzO0d/fcJp76Iz73g5eL1GnD7h+WG4UzY7RYKX3MxJjaLfjmpnLFJB237sQidWaYsTvAJwahBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkql0mmhnJdF3JY1JGo2IpU02BaB33Zz7/ZWI2NNYJwBqwe43kEzVUIekP9heb/v6oz1g4tidsf2M3QHaUnX3+8sRsdP2pyU9Zfu1iHhu4gMiYrWk1ZI0a9HCgl+uAzBRpS11ROzs/LtL0iOSljXZFIDeVRmQN8f2CYcvS/qqpFebbgxAb6rsfp8q6RHbhx//64h4otGuAPRs0lBHxHZJXyjQC4Aa8JEWkAyhBpIh1EAyhBpIhlADyRBqIBlCDSTTyNgdjVmDbw818tRt2v/tLxatN3vPoWK15q96sVitHWvPLVartK+dXGbMzwuD7x/zPrbUQDKEGkiGUAPJEGogGUINJEOogWQINZAMoQaSIdRAMoQaSKZSqG2fZHut7ddsb7F9QdONAehN1XO/75D0RER8y/ZMScc32BOAKZg01LbnSbpQ0vckKSJGJI002xaAXlXZ/V4sabeke2y/YntNZ/3vI0wcu3OIsTtAa6qEelDS+ZJWRcQSSQckrfzwgyJidUQsjYilM+Z+JPMACqkS6mFJwxFx+Au3azUecgB9aNJQR8RbknbYPrtz08WSNjfaFYCeVT36faOk+ztHvrdLuq65lgBMRaVQR8RGSUsb7gVADTijDEiGUAPJEGogGUINJEOogWQINZAMoQaSIdRAMs3M0gpJhcZA7Vz5pTKFJM18J4rVkqT5q9YVq7Xz4c8Xq3XNZ18qVuszW3cVqyVJK074d5E6d8wYPeZ9bKmBZAg1kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkJg217bNtb5zws8/2zSWaA9C9SU8TjYitks6TJNsDknZKeqThvgD0qNvd74sl/T0i/tFEMwCmrttQr5D0wNHuOGLszgHG7gBtqRzqzprfV0r63dHuP2LszhzG7gBt6WZLfZmkDRHxr6aaATB13YT6ah1j1xtA/6gU6s7o2kskPdxsOwCmqurYnQOSPtVwLwBqwBllQDKEGkiGUAPJEGogGUINJEOogWQINZAMoQaScUT9o2Rs75bU7dczT5G0p/Zm+kPW18bras8ZETH/aHc0Eupe2H45Ipa23UcTsr42Xld/YvcbSIZQA8n0U6hXt91Ag7K+Nl5XH+qb99QA6tFPW2oANSDUQDJ9EWrbl9reanub7ZVt91MH26fbfsb2ZtubbN/Udk91sj1g+xXbj7XdS51sn2R7re3XbG+xfUHbPXWr9ffUnQEBr2t8uaRhSS9JujoiNrfa2BTZPk3SaRGxwfYJktZL+sZ0f12H2f6RpKWSToyIK9rupy6275X0x4hY01lB9/iI2Nt2X93ohy31MknbImJ7RIxIelDSVS33NGUR8WZEbOhcflfSFkkL2u2qHrYXSrpc0pq2e6mT7XmSLpR0lyRFxMh0C7TUH6FeIGnHhOvDSvKf/zDbiyQtkfRiu53U5nZJt0g61HYjNVssabekezpvLdZ0Ft2cVvoh1KnZnivpIUk3R8S+tvuZKttXSNoVEevb7qUBg5LOl7QqIpZIOiBp2h3j6YdQ75R0+oTrCzu3TXu2hzQe6PsjIsvyysslXWn7DY2/VbrI9n3ttlSbYUnDEXF4j2qtxkM+rfRDqF+SdJbtxZ0DEyskPdpyT1Nm2xp/b7YlIm5ru5+6RMStEbEwIhZp/Hf1dERc03JbtYiItyTtsH1256aLJU27A5uV1v1uUkSM2r5B0pOSBiTdHRGbWm6rDsslXSvpb7Y3dm77aUQ83mJPmNyNku7vbGC2S7qu5X661vpHWgDq1Q+73wBqRKiBZAg1kAyhBpIh1EAyhBpIhlADyfwPUwXMKWC8q9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = 0.999\n",
    "env = FrozenLakeEnv(desc = MAP[0], is_slippery = True)\n",
    "print(\"Game Map:\")\n",
    "env.render()\n",
    "\n",
    "start_time = time.time()\n",
    "v, pi = sync_value_iteration_v1(env, beta = beta)\n",
    "v_np, pi_np  = np.array(v), np.array(pi)\n",
    "end_time = time.time()\n",
    "run_time['Sync Value Iteration v1'] = end_time - start_time\n",
    "print(\"time:\", run_time['Sync Value Iteration v1'])\n",
    "\n",
    "print_results(v, pi, map_size, env, beta, 'sync_vi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous Value Iteration Using GetSuccessors()\n",
    "The above version of value iteration can be very innefficient when the number of states is large because it iterates over all next states. In practice, it is usually the case that for any state $s$ and action $a$ most states have zero probability of being successors. We can exploit that fact to make value iteration more efficient. \n",
    "\n",
    "The goal of this part is to use GetSuccessors() function to decrease the running time. This function takes a state and an action as input and returns the possible next states (with non-zero transition probability) and their transition probabilities. this allows us to ignore all states with zero transition probability. Implement value iteration in the following cell following the previous implmentation. But, here, use the env.GetSuccessors() function ot limit the Bellman backup to only consider non-zero probability states in the summation over next states. Using this function you will not need the GetTransitionProb function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_value_iteration_v2(env, beta = 0.999, epsilon = 0.0001):\n",
    "    \n",
    "    A = env.GetActionSpace()\n",
    "    S = env.GetStateSpace()\n",
    "    \n",
    "    pi = [0] * S\n",
    "    v = [0] * S\n",
    "    \n",
    "    pi_new = [0] * S\n",
    "    v_new = [0] * S\n",
    "    \n",
    "    \n",
    "    bellman_error = float('inf')\n",
    "    while(bellman_error > epsilon):\n",
    "        bellman_error = 0\n",
    "        for state in range(S):\n",
    "            max_v = float('-inf')\n",
    "            max_a = 0\n",
    "            for action in range(A):\n",
    "                reward = env.GetReward(state, action)\n",
    "                state_sum = 0\n",
    "                for state_prob in env.GetSuccessors(state, action):\n",
    "                    state_sum += state_prob[1] * v[state_prob[0]]\n",
    "                state_sum *= beta\n",
    "                reward += state_sum\n",
    "                if reward > max_v:\n",
    "                    max_v = reward\n",
    "                    max_a = action\n",
    "            \n",
    "            #Update the policy and the v\n",
    "            pi_new[state] = max_a\n",
    "            v_new[state] = max_v\n",
    "            #Update the error\n",
    "            error = abs(v_new[state] - v[state])\n",
    "            if error > bellman_error:\n",
    "                bellman_error = error\n",
    "                \n",
    "        v = deepcopy(v_new)\n",
    "        pi = deepcopy(pi_new)\n",
    "        \n",
    "    return v, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see the output of your function and store the value and policy matrices to file. Note the time taken for this version versus the previous version of value iteration. The computation time should be significantly smaller for this later version that uses GetSuccessors. Because of this time savings, for the remainder of this assignment you should implement Bellman backups using GetSuccessors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Map:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "time: 0.2996504306793213\n",
      "\n",
      "State Value:\n",
      "\n",
      "[[  363.5    365.91   369.38   376.73   400.45   411.84   418.7    422.15]\n",
      " [  360.24   357.72   335.12   231.84   358.44   389.37   415.63   424.67]\n",
      " [  353.55   333.99   189.29 -1000.     173.63   227.87   389.72   428.36]\n",
      " [  339.83   306.42   225.01   -42.34    11.12 -1000.     269.05   436.45]\n",
      " [  290.6    139.46   -29.52 -1000.     -51.75    81.41   258.29   463.58]\n",
      " [  110.07 -1000.   -1000.    -309.32   -88.99    68.62 -1000.     498.87]\n",
      " [  -32.47 -1000.    -463.4   -463.4  -1000.     243.49 -1000.     720.18]\n",
      " [  -53.06  -187.65  -309.32 -1000.     262.9    625.53   734.24  1000.  ]]\n",
      "\n",
      "Policy:\n",
      "\n",
      "[[2 2 2 2 2 2 2 1]\n",
      " [3 3 3 3 3 2 2 1]\n",
      " [3 3 3 0 3 2 2 1]\n",
      " [3 0 0 0 3 0 2 1]\n",
      " [3 3 3 0 2 2 2 1]\n",
      " [3 0 0 2 2 1 0 1]\n",
      " [3 0 1 3 0 1 0 1]\n",
      " [3 0 0 0 2 2 2 0]]\n",
      "\n",
      "Average reward: 401.389\n",
      "\n",
      "Avereage discounted reward: 369.54066059769696\n",
      "\n",
      "State Value image view:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = 0.999\n",
    "env = FrozenLakeEnv(desc = MAP[0], is_slippery = True)\n",
    "print(\"Game Map:\")\n",
    "env.render()\n",
    "\n",
    "start_time = time.time()\n",
    "v, pi = sync_value_iteration_v2(env, beta = beta)\n",
    "v_np, pi_np  = np.array(v), np.array(pi)\n",
    "end_time = time.time()\n",
    "run_time['Sync Value Iteration v2'] = end_time - start_time\n",
    "print(\"time:\", run_time['Sync Value Iteration v2'])\n",
    "\n",
    "print_results(v, pi, map_size, env, beta, 'sync_vi_gs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Initialize Ray\n",
    "\n",
    "Now we are going to use Ray to develop distributed versions of the above value iteration algorithm. The first step of course is to initialize Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-02 11:40:41,651\tWARNING services.py:597 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-01-02 11:40:41,654\tINFO resource_spec.py:216 -- Starting Ray with 4.3 GiB memory available for workers and up to 0.94 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.21.44.163',\n",
       " 'redis_address': '172.21.44.163:33693',\n",
       " 'object_store_address': '/tmp/ray/session_2020-01-02_11-40-41_648822_1374/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-01-02_11-40-41_648822_1374/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2020-01-02_11-40-41_648822_1374'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ray.shutdown()\n",
    "ray.init(include_webui=False, ignore_reinit_error=True, redis_max_memory=10000000, object_store_memory=1008643200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Synchronous Value Iteration -- Version 1\n",
    "A simple way to distribute Value Iteration would be to implement each iteration by having a each state updated by a distinct worker. That is each state is updated by creating a work to do the Bellman backup for that state and then recording the result. In order to avoid creating an enormous number of workers, the first implementation will only allow a specified number of workers to be active at any time. After each iteration, the main process checks the Bellman error and if it is less than the specified epsilon it terminates. The following diagram demonstrates the architecture of such a system.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "                                +---------------+\n",
    "                                |               |\n",
    "                                | Main Process  |------------------------------------\n",
    "                                |               |                                   |\n",
    "                                |               |                                   |\n",
    "                                +---------------+                                   |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "     +---Re-init Worker-----+-------------------+-----Re-init Worker---+          Check\n",
    "     |                      |                   |                      |        Coverage\n",
    "+-----------+         +-----------+       +-----------+         +-----------+  Iteratively\n",
    "|           |         |           |       |           |         |           |       |\n",
    "|  Worker   |         |  Worker   |       |  Worker   |         |  Worker   |       |\n",
    "|  (env)    |         |  (env)    |       |  (env)    |         |  (env)    |       |        \n",
    "|           |         |           |       |           |         |           |       |\n",
    "+-----------+         +-----------+       +-----------+         +-----------+       |\n",
    "      ^                     ^                   ^                     ^             |\n",
    "      |                     |                   |                     |             |\n",
    "      +------ One-Value ----+---------+---------+----- One-Value -----+             |\n",
    "                                      |                                             |\n",
    "                                      |                                             |\n",
    "                              +----------------+                                    |             \n",
    "                              |                |                                    |                   \n",
    "                              |  Value Server  |-------------------------------------                        \n",
    "                              |                |                  \n",
    "                              +----------------+\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "A key part of this implementation is the Value Server, which is a Ray actor that workers interface with to update the value function at each iteration. In order to avoid \n",
    "\n",
    "You need to complete the following code by adding the Bellman backup operator to it. Once you implemented the function, run the following cell to test it and to store the value and policy matrices to file. Note that this implementation should replicate the results of the non-distributed version of synchronous value iteration. \n",
    "\n",
    "Importantly you should see that this version is significantly slower than the above non-distributed version. Think about why this might be the case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class VI_server_v1(object):\n",
    "    def __init__(self,size):\n",
    "        self.v_current = [0] * size\n",
    "        self.pi = [0] * size\n",
    "        self.v_new = [0] * size\n",
    "        \n",
    "    def get_value_and_policy(self):\n",
    "        return self.v_current, self.pi\n",
    "    \n",
    "    def update(self, update_index, update_v, update_pi):\n",
    "        self.v_new[update_index] = update_v\n",
    "        self.pi[update_index] = update_pi\n",
    "    \n",
    "    def get_error_and_update(self):\n",
    "        max_error = 0\n",
    "        for i in range(len(self.v_current)):\n",
    "            error = abs(self.v_new[i] - self.v_current[i])\n",
    "            if error > max_error:\n",
    "                max_error = error\n",
    "            self.v_current[i] = self.v_new[i]\n",
    "            \n",
    "        return max_error\n",
    "    \n",
    "@ray.remote\n",
    "def VI_worker_v1(VI_server, data, worker_id, update_state):\n",
    "        env, workers_num, beta, epsilon = data\n",
    "        A = env.GetActionSpace()\n",
    "        S = env.GetStateSpace()\n",
    "            \n",
    "        # get shared variable      \n",
    "        V, _ = ray.get(VI_server.get_value_and_policy.remote())\n",
    "        \n",
    "        # bellman backup\n",
    "        max_v = float('-inf')\n",
    "        max_a = 0\n",
    "        for action in range(A):\n",
    "            reward = env.GetReward(update_state, action)\n",
    "            state_sum = 0\n",
    "            for state_prob in env.GetSuccessors(update_state, action):\n",
    "                state_sum += state_prob[1] * V[state_prob[0]]\n",
    "            state_sum *= beta\n",
    "            reward += state_sum\n",
    "            if reward > max_v:\n",
    "                max_v = reward\n",
    "                max_a = action\n",
    "        \n",
    "        VI_server.update.remote(update_state, max_v, max_a)\n",
    "        \n",
    "        # return ith worker\n",
    "        return worker_id\n",
    "                    \n",
    "def sync_value_iteration_distributed_v1(env, beta = 0.999, epsilon = 0.01, workers_num = 4, stop_steps = 2000):\n",
    "    S = env.GetStateSpace()\n",
    "    VI_server = VI_server_v1.remote(S)\n",
    "    workers_list = []\n",
    "    data_id = ray.put((env, workers_num, beta, epsilon))\n",
    "    \n",
    "    start = 0\n",
    "    # start the all worker, store their id in a list\n",
    "    for i in range(workers_num):\n",
    "        w_id = VI_worker_v1.remote(VI_server, data_id, i, start)\n",
    "        workers_list.append(w_id)\n",
    "        start += 1\n",
    "    \n",
    "    error = float('inf')\n",
    "    while error > epsilon:\n",
    "        for update_state in range(start, S):\n",
    "            # Wait for one worker finishing, get its reuslt, and delete it from list\n",
    "            finished_worker_id = ray.wait(workers_list, num_returns = 1, timeout = None)[0][0]\n",
    "            finish_worker = ray.get(finished_worker_id)\n",
    "            workers_list.remove(finished_worker_id)\n",
    "\n",
    "            # start a new worker, and add it to the list\n",
    "            w_id = VI_worker_v1.remote(VI_server, data_id, finish_worker, update_state)\n",
    "            workers_list.append(w_id)\n",
    "        start = 0\n",
    "        error = ray.get(VI_server.get_error_and_update.remote())\n",
    "\n",
    "    v, pi = ray.get(VI_server.get_value_and_policy.remote())\n",
    "    return v, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Map:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:07.075071  2059 direct_actor_transport.h:307] client skipping requests 1 to 1\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:07.075132  2059 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 2\n",
      "\u001b[2m\u001b[36m(pid=2062)\u001b[0m E1230 11:53:07.075359  2230 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v1,update, task_id=5e2a93c4914c650f2c5a7f840100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=2c5a7f840100, actor_caller_id=a8a4a094f2f04ac1ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=2060)\u001b[0m E1230 11:53:09.504726  2197 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v1,update, task_id=f170e2ab71169cbd2c5a7f840100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=2c5a7f840100, actor_caller_id=bd2bdf2007a6900dffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:09.504052  2059 direct_actor_transport.h:307] client skipping requests 1 to 1\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:09.504118  2059 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 2\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:12.624544  2059 direct_actor_transport.h:307] client skipping requests 1 to 1\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:12.624588  2059 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 2\n",
      "\u001b[2m\u001b[36m(pid=2064)\u001b[0m E1230 11:53:12.624810  2228 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v1,update, task_id=4755fae843e8466b2c5a7f840100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=2c5a7f840100, actor_caller_id=c875a551e2a59d36ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=2060)\u001b[0m E1230 11:53:15.506162  2197 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v1,update, task_id=176cde499f7e0cea2c5a7f840100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=2c5a7f840100, actor_caller_id=830e3f022ddfaa55ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:15.505895  2059 direct_actor_transport.h:307] client skipping requests 1 to 1\n",
      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m E1230 11:53:15.505954  2059 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 2\n",
      "time: 12.376242399215698\n",
      "\n",
      "State Value:\n",
      "\n",
      "[[  363.5    365.91   369.38   376.73   400.45   411.84   418.7    422.15]\n",
      " [  360.23   357.71   335.12   231.84   358.44   389.37   415.63   424.67]\n",
      " [  353.54   333.99   189.29 -1000.     173.63   227.87   389.72   428.36]\n",
      " [  339.82   306.41   225.     -42.35    11.12 -1000.     269.05   436.45]\n",
      " [  290.59   139.45   -29.53 -1000.     -51.75    81.41   258.29   463.58]\n",
      " [  110.05 -1000.   -1000.    -309.32   -88.99    68.62 -1000.     498.87]\n",
      " [  -32.49 -1000.    -463.43  -463.41 -1000.     243.49 -1000.     720.18]\n",
      " [  -53.08  -187.68  -309.35 -1000.     262.9    625.53   734.24  1000.  ]]\n",
      "\n",
      "Policy:\n",
      "\n",
      "[[2 2 2 2 2 2 2 1]\n",
      " [3 3 3 3 3 2 2 1]\n",
      " [3 3 3 0 3 2 2 1]\n",
      " [3 0 0 0 3 0 2 1]\n",
      " [3 3 3 0 2 2 2 1]\n",
      " [3 0 0 2 2 1 0 1]\n",
      " [3 0 1 3 0 1 0 1]\n",
      " [3 0 0 0 2 2 2 0]]\n",
      "\n",
      "Average reward: 371.388\n",
      "\n",
      "Avereage discounted reward: 387.34750697554693\n",
      "\n",
      "State Value image view:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAALgUlEQVR4nO3df6jddR3H8ddr997NuenEXCKbuGUmmJCTsbCFkGJpikYUzNBICiFQlAKb/dd/9Y/oH7IYUxM0raaCiGmCiinLdHOV25ysYewubRs255Z2d+/e/XHP7E437/ec+/1+vue+fT7gsvOL834f7l73+z3f8z2ftyNCAPKY0XYDAOpFqIFkCDWQDKEGkiHUQDKDTTzp0LzZMevUeU08daucuKCV81OQrL+z997ap5G97x21WiOhnnXqPJ1353ebeOpWzXDZ//guWG/mjLFitUq+rtK/s1L1Xrj+N8fuoUgHAIoh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkqkUatuX2t5qe5vtlU03BaB3k4ba9oCkOyVdJukcSVfbPqfpxgD0psqWepmkbRGxPSJGJD0o6apm2wLQqyqhXiBpx4Trw53bjmD7etsv23559J336uoPQJdqO1AWEasjYmlELB2cN7uupwXQpSqh3inp9AnXF3ZuA9CHqoT6JUln2V5se6akFZIebbYtAL2adJGEiBi1fYOkJyUNSLo7IjY13hmAnlRa+SQiHpf0eMO9AKgBZ5QByRBqIBlCDSRDqIFkCDWQDKEGkiHUQDKNTOgo6VCUG6wyMjZQrJYk7d1f7hz6U048UKzWrMHRcrUGytXqF2ypgWQINZAMoQaSIdRAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kEyVCR13295l+9USDQGYmipb6l9JurThPgDUZNJQR8Rzkt4u0AuAGtT2npqxO0B/YOwOkAxHv4FkCDWQTJWPtB6QtE7S2baHbX+/+bYA9KrKLK2rSzQCoB7sfgPJEGogGUINJEOogWQINZAMoQaSIdRAMo2N3Sk1Dmf0ULm/S3v2zi1WS5LO/M7GYrW23bekWK2hmeVG4Sw4+Z1itSRp9uDBovWOhi01kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkqmyRtnptp+xvdn2Jts3lWgMQG+qnPs9KunHEbHB9gmS1tt+KiI2N9wbgB5UGbvzZkRs6Fx+V9IWSQuabgxAb7p6T217kaQlkl48yn0fjN05yNgdoDWVQ217rqSHJN0cEfs+fP/EsTtDjN0BWlMp1LaHNB7o+yPi4WZbAjAVVY5+W9JdkrZExG3NtwRgKqpsqZdLulbSRbY3dn6+3nBfAHpUZezO85LKrE0EYMo4owxIhlADyRBqIBlCDSRDqIFkCDWQDKEGkiHUQDKNzNIKWWOFZmkdHCv3d2lg4FCxWpK0/RcXlCu2J4qVOuPmV4rV+ucj5xSrJUmLT367SB3r2L8vttRAMoQaSIZQA8kQaiAZQg0kQ6iBZAg1kAyhBpIh1EAyVRYePM72n23/pTN252clGgPQmyqnif5X0kURsb+zVPDztn8fEX9quDcAPaiy8GBI2t+5OtT5KXeiMICuVF3Mf8D2Rkm7JD0VER87dmf0nf/U3SeAiiqFOiLGIuI8SQslLbN97lEe88HYncF5x9fdJ4CKujr6HRF7JT0j6dJm2gEwVVWOfs+3fVLn8mxJl0h6renGAPSmytHv0yTda3tA438EfhsRjzXbFoBeVTn6/VeNz6QGMA1wRhmQDKEGkiHUQDKEGkiGUAPJEGogGUINJEOogWSaGbsT1vsjQ0089UfsfXtOkTqSNLBnZrFaknTmT9YVq7X95+VG/Lz+y2XFas2JA8VqSdJxAweL1GHsDvAJQqiBZAg1kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkKoe6s6D/K7ZZdBDoY91sqW+StKWpRgDUo+rYnYWSLpe0ptl2AExV1S317ZJukXToWA84cpZW2W/GAPi/KhM6rpC0KyLWf9zjjpylVe7rkACOVGVLvVzSlbbfkPSgpIts39doVwB6NmmoI+LWiFgYEYskrZD0dERc03hnAHrC59RAMl0tZxQRz0p6tpFOANSCLTWQDKEGkiHUQDKEGkiGUAPJEGogGUINJNPI2J2xgzO0d/fcJp76Iz73g5eL1GnD7h+WG4UzY7RYKX3MxJjaLfjmpnLFJB237sQidWaYsTvAJwahBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkCDWQDKEGkql0mmhnJdF3JY1JGo2IpU02BaB33Zz7/ZWI2NNYJwBqwe43kEzVUIekP9heb/v6oz1g4tidsf2M3QHaUnX3+8sRsdP2pyU9Zfu1iHhu4gMiYrWk1ZI0a9HCgl+uAzBRpS11ROzs/LtL0iOSljXZFIDeVRmQN8f2CYcvS/qqpFebbgxAb6rsfp8q6RHbhx//64h4otGuAPRs0lBHxHZJXyjQC4Aa8JEWkAyhBpIh1EAyhBpIhlADyRBqIBlCDSTTyNgdjVmDbw818tRt2v/tLxatN3vPoWK15q96sVitHWvPLVartK+dXGbMzwuD7x/zPrbUQDKEGkiGUAPJEGogGUINJEOogWQINZAMoQaSIdRAMoQaSKZSqG2fZHut7ddsb7F9QdONAehN1XO/75D0RER8y/ZMScc32BOAKZg01LbnSbpQ0vckKSJGJI002xaAXlXZ/V4sabeke2y/YntNZ/3vI0wcu3OIsTtAa6qEelDS+ZJWRcQSSQckrfzwgyJidUQsjYilM+Z+JPMACqkS6mFJwxFx+Au3azUecgB9aNJQR8RbknbYPrtz08WSNjfaFYCeVT36faOk+ztHvrdLuq65lgBMRaVQR8RGSUsb7gVADTijDEiGUAPJEGogGUINJEOogWQINZAMoQaSIdRAMs3M0gpJhcZA7Vz5pTKFJM18J4rVkqT5q9YVq7Xz4c8Xq3XNZ18qVuszW3cVqyVJK074d5E6d8wYPeZ9bKmBZAg1kAyhBpIh1EAyhBpIhlADyRBqIBlCDSRDqIFkJg217bNtb5zws8/2zSWaA9C9SU8TjYitks6TJNsDknZKeqThvgD0qNvd74sl/T0i/tFEMwCmrttQr5D0wNHuOGLszgHG7gBtqRzqzprfV0r63dHuP2LszhzG7gBt6WZLfZmkDRHxr6aaATB13YT6ah1j1xtA/6gU6s7o2kskPdxsOwCmqurYnQOSPtVwLwBqwBllQDKEGkiGUAPJEGogGUINJEOogWQINZAMoQaScUT9o2Rs75bU7dczT5G0p/Zm+kPW18bras8ZETH/aHc0Eupe2H45Ipa23UcTsr42Xld/YvcbSIZQA8n0U6hXt91Ag7K+Nl5XH+qb99QA6tFPW2oANSDUQDJ9EWrbl9reanub7ZVt91MH26fbfsb2ZtubbN/Udk91sj1g+xXbj7XdS51sn2R7re3XbG+xfUHbPXWr9ffUnQEBr2t8uaRhSS9JujoiNrfa2BTZPk3SaRGxwfYJktZL+sZ0f12H2f6RpKWSToyIK9rupy6275X0x4hY01lB9/iI2Nt2X93ohy31MknbImJ7RIxIelDSVS33NGUR8WZEbOhcflfSFkkL2u2qHrYXSrpc0pq2e6mT7XmSLpR0lyRFxMh0C7TUH6FeIGnHhOvDSvKf/zDbiyQtkfRiu53U5nZJt0g61HYjNVssabekezpvLdZ0Ft2cVvoh1KnZnivpIUk3R8S+tvuZKttXSNoVEevb7qUBg5LOl7QqIpZIOiBp2h3j6YdQ75R0+oTrCzu3TXu2hzQe6PsjIsvyysslXWn7DY2/VbrI9n3ttlSbYUnDEXF4j2qtxkM+rfRDqF+SdJbtxZ0DEyskPdpyT1Nm2xp/b7YlIm5ru5+6RMStEbEwIhZp/Hf1dERc03JbtYiItyTtsH1256aLJU27A5uV1v1uUkSM2r5B0pOSBiTdHRGbWm6rDsslXSvpb7Y3dm77aUQ83mJPmNyNku7vbGC2S7qu5X661vpHWgDq1Q+73wBqRKiBZAg1kAyhBpIh1EAyhBpIhlADyfwPUwXMKWC8q9gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta = 0.999\n",
    "env = FrozenLakeEnv(desc = MAP[0], is_slippery = True)\n",
    "print(\"Game Map:\")\n",
    "env.render()\n",
    "\n",
    "start_time = time.time()\n",
    "v, pi = sync_value_iteration_distributed_v1(env, beta = beta, workers_num = 4)\n",
    "v_np, pi_np  = np.array(v), np.array(pi)\n",
    "end_time = time.time()\n",
    "run_time['Sync distributed v1'] = end_time - start_time\n",
    "print(\"time:\", run_time['Sync distributed v1'])\n",
    "\n",
    "print_results(v, pi, map_size, env, beta, 'dist_vi_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Synchronous Value Iteration -- Version 2\n",
    "\n",
    "One way to improve the above approach is to create a limited number of workers and have each worker perform backups on a batch of states. Effectively, this approach partitions the state space and uses a worker to handle each state subset of the partition. The following diagram demonstrates the architecture of such a system.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "                                +---------------+\n",
    "                                |               |\n",
    "                                | Main Process  |------------------------------------\n",
    "                                |               |                                   |\n",
    "                                |               |                                   |\n",
    "                                +---------------+                                   |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "                                        |                                           |\n",
    "     +---Re-init Worker-----+-------------------+-----Re-init Worker---+          Check\n",
    "     |                      |                   |                      |        Coverage\n",
    "+-----------+         +-----------+       +-----------+         +-----------+  Iteratively\n",
    "|           |         |           |       |           |         |           |       |\n",
    "|  Worker   |         |  Worker   |       |  Worker   |         |  Worker   |       |\n",
    "|  (env)    |         |  (env)    |       |  (env)    |         |  (env)    |       |        \n",
    "|           |         |           |       |           |         |           |       |\n",
    "+-----------+         +-----------+       +-----------+         +-----------+       |\n",
    "      ^                     ^                   ^                     ^             |\n",
    "      |                     |                   |                     |             |\n",
    "      +---- Batch-Value ----+---------+---------+---- Batch-Value ----+             |\n",
    "                                      |                                             |\n",
    "                                      |                                             |\n",
    "                              +----------------+                                    |             \n",
    "                              |                |                                    |                   \n",
    "                              |  Value Server  |-------------------------------------                        \n",
    "                              |                |                  \n",
    "                              +----------------+\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "In this section, you should implement the idea described above.\n",
    "- Partition the states into batches. The number of batches should be equal to the number of the workers.\n",
    "- Create workers to handle each batch and run them\n",
    "- Terminate the workers once the error is less than the given epsilon\n",
    "\n",
    "Again, this implementation should exactly emulate the result of each iteration of non-distributed value iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class VI_server_v2(object):\n",
    "    def __init__(self,size):\n",
    "        self.v_current = [0] * size\n",
    "        self.pi = [0] * size\n",
    "        self.v_new = [0] * size\n",
    "        \n",
    "    def get_value_and_policy(self):\n",
    "        return self.v_current, self.pi\n",
    "    \n",
    "    def update(self, update_index, update_v, update_pi):\n",
    "        self.v_new[update_index] = update_v\n",
    "        self.pi[update_index] = update_pi\n",
    "    \n",
    "    def get_error_and_update(self):\n",
    "        max_error = 0\n",
    "        for i in range(len(self.v_current)):\n",
    "            error = abs(self.v_new[i] - self.v_current[i])\n",
    "            if error > max_error:\n",
    "                max_error = error\n",
    "            self.v_current[i] = self.v_new[i]\n",
    "            \n",
    "        return max_error\n",
    "    \n",
    "@ray.remote\n",
    "def VI_worker_v2(VI_server, data, worker_id, start_state, end_state):\n",
    "        env, workers_num, beta, epsilon = data\n",
    "        A = env.GetActionSpace()\n",
    "        S = env.GetStateSpace()\n",
    "        \n",
    "        V, _ = ray.get(VI_server.get_value_and_policy.remote())\n",
    "        \n",
    "        for update_state in range(start_state, end_state):\n",
    "            # bellman backup\n",
    "            max_v = float('-inf')\n",
    "            max_a = 0\n",
    "            for action in range(A):\n",
    "                reward = env.GetReward(update_state, action)\n",
    "                state_sum = 0\n",
    "                for state_prob in env.GetSuccessors(update_state, action):\n",
    "                    state_sum += state_prob[1] * V[state_prob[0]]\n",
    "                state_sum *= beta\n",
    "                reward += state_sum\n",
    "                if reward > max_v:\n",
    "                    max_v = reward\n",
    "                    max_a = action\n",
    "\n",
    "            VI_server.update.remote(update_state, max_v, max_a)\n",
    "                    \n",
    "def sync_value_iteration_distributed_v2(env, beta = 0.999, epsilon = 0.01, workers_num = 4, stop_steps = 2000):\n",
    "    S = env.GetStateSpace()\n",
    "    VI_server = VI_server_v2.remote(S)\n",
    "    workers_list = []\n",
    "    data_id = ray.put((env, workers_num, beta, epsilon))\n",
    "    \n",
    "    batch_size = int(S / workers_num)\n",
    "    start_state = 0\n",
    "    end_state = batch_size\n",
    "    # start the all worker, store their id in a list\n",
    "    for i in range(workers_num):\n",
    "        w_id = VI_worker_v2.remote(VI_server, data_id, i, start_state, end_state)\n",
    "        workers_list.append(w_id)\n",
    "        start_state += batch_size\n",
    "        if start_state > S:\n",
    "            start_state = S\n",
    "        end_state += batch_size\n",
    "        if end_state > S:\n",
    "            end_state = S\n",
    "\n",
    "    error = float('inf')\n",
    "    while error > epsilon:\n",
    "        start_state = 0\n",
    "        end_state = batch_size\n",
    "        \n",
    "        for i in range(workers_num):\n",
    "            finished_worker_id = ray.wait(workers_list, num_returns = 1, timeout = None)[0][0]\n",
    "            finish_worker = ray.get(finished_worker_id)\n",
    "            workers_list.remove(finished_worker_id)\n",
    "            \n",
    "            w_id = VI_worker_v2.remote(VI_server, data_id, finish_worker, start_state, end_state)\n",
    "            workers_list.append(w_id)\n",
    "            \n",
    "            \n",
    "            start_state += batch_size\n",
    "            if start_state > S:\n",
    "                start_state = S\n",
    "            end_state += batch_size\n",
    "            if end_state > S:\n",
    "                end_state = S\n",
    "        \n",
    "        error = ray.get(VI_server.get_error_and_update.remote())\n",
    "    \n",
    "    v, pi = ray.get(VI_server.get_value_and_policy.remote())\n",
    "    return v, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to see the running time of your code. This code stores the policy and state values to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Map:\n",
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-51fc04ad00b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msync_value_iteration_distributed_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mv_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_np\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b1776deb9eb5>\u001b[0m in \u001b[0;36msync_value_iteration_distributed_v2\u001b[0;34m(env, beta, epsilon, workers_num, stop_steps)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVI_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_and_update\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.141852  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=2333a3b1e00beb1a45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.142048  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a55accaece39422c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=2}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.143280  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=ac723b07f029536d45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=3}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.144176  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=3fef0d1c9b5fe53245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=4}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.145958  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=80e6b1084dde14c945b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=5}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.146744  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=657f0e3626f7090f45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=6}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.147989  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=c861f958e7dae98c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=7}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.148061  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=05224980094103c645b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=8}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.148180  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=667f9133410d978b45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=9}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.148283  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5d53d5d8ecf6d35c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=10}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.148393  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=cb22379c96563d9e45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=11}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.148504  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=0ffa8eb81e1e7d9945b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=12}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.149432  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5a729d2bbf46ecfa45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=13}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.150382  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=64cc7a08ef7b8aa245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=14}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.151021  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=f893df0f0a05094e45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=15}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.151401  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=05f806765141e4f645b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=55c3b2b635949d81ffffffff0100, actor_counter=16}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.154592  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=c03af95cd68014c345b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.154657  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=da8983ff5a0bdc0245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=2}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.155055  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=7dc495747cf84e3c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=3}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.155304  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=4a49c3f8c3954a0c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=4}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.155748  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5fa1679c3c4e935945b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=5}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163369  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=250adcfa7d027d9a45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=6}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163633  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=54ecae57943fac2245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=7}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163702  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=8bfcb412eb2e3ec345b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=8}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163744  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a48edf5aa309d26645b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=9}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163911  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5f21cf9651ae662545b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=10}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.163974  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=62d8b5555070098145b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=11}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.164017  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=b708b31b6d34da5845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=12}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.164212  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=13a1c95388a94db245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=13}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.164310  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=10cabe900ee88d8845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=14}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.164389  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=6f3ddab1fcb77bd345b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=15}\n",
      "\u001b[2m\u001b[36m(pid=1427)\u001b[0m E0102 11:40:47.164489  1558 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a4e2b70e6875485745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=15c675b22d037e3bffffffff0100, actor_counter=16}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.159761  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=be330f1faba7ddd945b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.159983  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=f27444e7e8c8d4c145b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=2}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160038  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=3920f21211be7d6045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=3}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160100  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=db969a27a0c32c1a45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=4}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160161  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=33e4af3bfc54654045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=5}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160209  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=08148101d1ecb76945b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=6}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160290  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=7c039db22c4edc9745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=7}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160454  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=d02cbbebf390ec5045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=8}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160674  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=1f7521122ec2cdb845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=9}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160802  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=05205ce17e7a148545b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=10}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.160939  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a14bd2be9043c42e45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=11}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.161042  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=9c9b066ece8c9b7445b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=12}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.161157  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=13c60f3033d7162f45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=13}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.161197  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=1494597d8ded421645b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=14}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.164902  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=daeca0c7d943ed7745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=15}\n",
      "\u001b[2m\u001b[36m(pid=1423)\u001b[0m E0102 11:40:47.164968  1577 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=4c7b4597f29b205745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=276fa5c994b5ce43ffffffff0100, actor_counter=16}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.155194  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=add0b4c18b410aeb45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.155627  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=3901a018baacb1ec45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=2}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.162492  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=fe9c8d2d9b3f129b45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=3}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.162612  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=2f48f6e70714b8a245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=4}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.162655  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a978712eb38ce5b445b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=5}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.162792  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=37a0e5c656ccc43b45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=6}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.162974  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=4d0820923eee2c8a45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=7}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.163023  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=586c9dad612d8f4e45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=8}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.163051  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=924686072116c3d445b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=9}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.163211  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=eed4d69e96e1e8d345b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=10}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.163277  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=686e6e45ccdd608745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=11}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.164561  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=9783145cc7e6b76e45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=12}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.164633  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=958d2e1e56297ef245b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=13}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.165190  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=17a66ecb0b694b2845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=14}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.165251  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5ed0c11de9cbe4b845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=15}\n",
      "\u001b[2m\u001b[36m(pid=1424)\u001b[0m E0102 11:40:47.165304  1587 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=628897e9d5a6110045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=8603ac10b8c093b3ffffffff0100, actor_counter=16}\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.140921  1430 direct_actor_transport.h:307] client skipping requests 1 to 16\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.141363  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.141553  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 2 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.143096  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 3 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.143973  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 4 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.145781  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 5 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.146576  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 6 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.147850  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 7 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.147955  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 8 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.148056  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 9 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.148152  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 10 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.148249  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 11 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.148349  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 12 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.149302  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 13 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.150243  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 14 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.150892  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 15 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.151268  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 16 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154145  1430 direct_actor_transport.h:307] client skipping requests 1 to 16\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154188  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154273  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 2 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154374  1430 direct_actor_transport.h:307] client skipping requests 1 to 16\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154397  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154479  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 3 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154557  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 2 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154640  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 4 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154742  1430 direct_actor_transport.h:307] client skipping requests 1 to 16\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154767  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154893  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 3 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.154976  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 2 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.155095  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 4 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.155403  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 5 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.155527  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 5 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.158694  1430 direct_actor_transport.h:307] client skipping requests 1 to 16\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.158733  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 1 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.158896  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 2 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.158988  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 3 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.159631  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 4 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.159780  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 5 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160006  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 6 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160163  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 7 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160292  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 8 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160460  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 9 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160636  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 10 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160774  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 11 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.160887  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 12 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161021  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 13 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161103  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 14 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161177  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 6 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161275  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 7 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161367  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 8 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161459  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 9 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161571  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 10 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161705  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 11 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161823  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 12 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.161933  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 13 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162026  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 14 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162101  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 15 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162191  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 16 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162292  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 3 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162398  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 4 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162478  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 5 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162606  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 6 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162719  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 7 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162802  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 8 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.162912  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 9 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163023  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 10 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163121  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 11 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163198  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 6 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163329  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 7 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163408  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 8 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163503  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 9 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163606  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 10 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163712  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 11 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.163813  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 12 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164067  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 13 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164197  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 14 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164301  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 15 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164357  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 16 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164412  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 12 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164505  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 13 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164608  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 15 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164710  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 16 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164783  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 14 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164873  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 15 < 17\n",
      "\u001b[2m\u001b[36m(pid=1430)\u001b[0m E0102 11:40:47.164958  1430 direct_actor_transport.h:333] Cancelling stale RPC with seqno 16 < 17\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.154688  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=bf10079b20341da045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=1}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.155026  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=c6243b26bc67213445b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=2}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.155100  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=e559aa54be29289145b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=3}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.155218  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=4e6d388c65aa34b045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=4}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.155617  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=5e60929fceb9532645b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=5}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161375  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=2b1dbf17405fec5a45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=6}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161434  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=8ec7dca4e8b551af45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=7}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161492  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=64ee969394265c2c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=8}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161605  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=dd437a7a30b9f1c545b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=9}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161725  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=ef5abd15cb978e9845b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=10}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161880  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=703b09bf1846402045b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=11}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.161947  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=2cdd1a243e14614745b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=12}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.162088  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=a9186866628bab1c45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=13}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.162145  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=57e265edbaf69f6345b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=14}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.162433  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=343d4242ba41e4e545b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=15}\n",
      "\u001b[2m\u001b[36m(pid=1426)\u001b[0m E0102 11:40:47.162482  1593 task_manager.cc:116] Task failed: IOError: 2: client cancelled stale rpc: Type=ACTOR_TASK, Language=PYTHON, function_descriptor=__main__,VI_server_v2,update, task_id=e5923ee4c20fb88d45b95b1c0100, job_id=0100, num_args=6, num_returns=2, actor_task_spec={actor_id=45b95b1c0100, actor_caller_id=9d28cb176c7f7501ffffffff0100, actor_counter=16}\n"
     ]
    }
   ],
   "source": [
    "beta = 0.999\n",
    "env = FrozenLakeEnv(desc = MAP[0], is_slippery = True)\n",
    "print(\"Game Map:\")\n",
    "env.render()\n",
    "\n",
    "start_time = time.time()\n",
    "v, pi = sync_value_iteration_distributed_v2(env, beta = beta, workers_num = 4)\n",
    "v_np, pi_np  = np.array(v), np.array(pi)\n",
    "end_time = time.time()\n",
    "run_time['Sync distributed v2'] = end_time - start_time\n",
    "print(\"time:\", run_time['Sync distributed v2'])\n",
    "print_results(v, pi, map_size, env, beta, 'dist_vi_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of different approachs\n",
    "\n",
    "Run the following cell to compare the running time of different approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All:\n",
      "Sync Value Iteration v2: 0.2996504306793213\n",
      "\n",
      "Sync Value Iteration v1: 0.7277002334594727\n",
      "\n",
      "Sync distributed v2: 0.7444186210632324\n",
      "\n",
      "Sync distributed v1: 12.376242399215698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "temp_dict = deepcopy(run_time)\n",
    "print(\"All:\")\n",
    "for _ in range(len(temp_dict)):\n",
    "    min_v = float('inf')\n",
    "    for k, v in temp_dict.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if v < min_v:\n",
    "            min_v = v\n",
    "            name = k\n",
    "    temp_dict[name] = float('inf')\n",
    "    print(name + \": \" + str(min_v))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "Write a report that includes the following:\n",
    "- A plot that shows the running time of the above 4 approaches agianst the map sizes f 8, 16 and 32. \n",
    "- A plot that shows the running time of both distributed approaches agianst the number of the workers with 2, 4 and 8 workers.\n",
    "- Breifly explain why the second distributed method is faster than the first one?\n",
    "- Compere the best distributed method with the best non-distributed appraoch. Which one is better? Briefly explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Synchronous VI Competition\n",
    "In this part, you should design and implement your own distributed synchronous VI method based on what you have learned in the previous parts. Your implementation has the following constraints:\n",
    "- It must terminate and return a value function (and corresponding greedy policy) that satisfies the specified Bellman error threshold\n",
    "- It must be iterative in the sense that it produces the same sequence of value functions as non-distributed synchronous value iteration\n",
    "\n",
    "For this part, you should create a stand alone python file named `competition.py`. You can copy the needed functions from this notebook to your file. Your code should contain a main function called `fast_value_iteration` with the following exact signiture: \n",
    "\n",
    "`def fast_value_iteration(env, beta = 0.999, epsilon = 0.01, workers_num = 4)`\n",
    "\n",
    "Here epsilon is the Bellman error threshold and worker_num is the maximum number of workers. This function should return policy and value vectors that satsify the Bellman error constraint. \n",
    "\n",
    "To test your code, you should use an exclusive compution node of DevCloud. You can use the `qsub -I -lselect=1` command to connect to a computation node and run your code on it. We may test your programs on problems as large as 100x100 FrozenLake environments. \n",
    "\n",
    "Some possible ideas to consider\n",
    "\n",
    "- How should the number of workers be selected and how should states be partitioned across workers?\n",
    "- Are there alternative protocols between the server and workers?\n",
    "- Where are the communication bottlenecks in the system and how might they be improved? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "Submit a zip file to Canvas that contains:\n",
    "- completed version of this notebook\n",
    "- the .pkl files generated by print_results function for your runs on map of size 8x8\n",
    "- a python file for distributed VI competition\n",
    "- your PDF report file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
